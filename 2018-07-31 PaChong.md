一、什么是爬虫？  
  - 爬虫：就是抓取网页数据的程序；
  
二、爬虫怎么抓取网页数据：  
  - 网页三大特征：  
    - 网页都有自己唯一的URL（统一资源定位符）地址，来进行定位；  
    - 网页都使用HTML（超文本标记语言）来描述页面信息；   
    - 网页都使用HTTP/HTTPS(超文本传输协议)来传输HTML数据；
    
  - 爬虫的设计思路：
    - 首先确定需要爬取的网页URL地址；  
    - 通过HTTP协议来获取对应的HTML页面；    
    - 提取HTML页面有用的数据；  
      - 如果是需要的数据保存起来；  
      - 如果是页面里其他的URL,那就继续执行第二步；  
      
三、爬虫：
  - 如何获取HTML页面：
    - HTTP请求的处理，urllib、URLlib2、requests  
    - 处理后的请求可以模拟浏览器发送请求，获取服务器响应文件  
  - 解析服务器响应的内容：  
  
